<predefined> ::='''def UNET(input_size=(592,592,3)):\n\tinputs = Input(input_size)\n\tx=inputs\n\t<s>\n\toutputs=Conv2D(1, (1, 1), padding="same", activation= <activation>, data_format=None)(x)\n\tmodel = Model(inputs = [inputs], outputs = [outputs])\n\tmodel.compile(optimizer = <optimisation>, loss = 'binary_crossentropy', metrics = ['accuracy'])\n\tmodel.summary()\n\treturn model\n
'''
<s>::=<unet>(1)

<unet>(A)::= <down>(A)\n\t<spatial>\n\t<up>(A)
          | <down>(A)\n\t<unet>(A+1)\n\t<up>(A)
<down> ::= <conv>\n\t<drop_type>\n\t<Batch>\n\t<pool>
<up> ::= <transpose>\n\t<drop_type>\n\t<Batch>
<transpose> ::= x = Conv2DTranspose(<filters>,(2, 2), strides=(2, 2), padding = <padding>)(x)
<spatial> ::= x = spatial_attention(x)
<conv> ::= x = Conv2D(<filters>,<kernel>, activation = <activation>, padding = <padding>, kernel_initializer = 'he_normal')(x)
<pool> ::= x =  <pooling>(pool_size=(2, 2), padding='same' )(x)
<drop_type> ::= <Dropout> | <DropBlock>
<Batch> ::= x = BatchNormalization()(x)
<DropBlock> ::= x = DropBlock2D(block_size = <block_size>, keep_prob = <keep_prob>)(x)
<Dropout> ::= x = Dropout(<rate>)(x)
<activation> ::= 'relu' | 'sigmoid' | 'softmax' | 'softplus' | 'softsign' | 'tanh' | 'selu' | 'elu' | 'LeakyReLU'
<pooling> ::= MaxPooling2D | AveragePooling2D
<rate> ::= 0.4 | 0.5 | 0.6
<optimisation> ::= 'Adam' | 'sgd' | 'adamax' | 'adagrad' | 'Nadam' | 'Ftrl' | 'Adadelta' | 'RMSprop'
<filters> ::= 16 | 32 | 64 | 128 | 256
<kernel> ::= (1, 1) | (2, 2) | (3, 3) | (5, 5)
<block_size> ::= 7 | 9
<keep_prob> ::= 0.8 | 0.9
<padding> ::= "valid" | "same"
